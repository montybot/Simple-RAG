# .env.example - Copy to .env and fill in the values

# ============================================================================
# LLM Configuration - Choose ONE provider below
# ============================================================================

# Option 1: OpenAI (Default)
OPENAI_API_KEY=sk-your-key-here
MODEL_NAME=gpt-4-turbo-preview
# Other options: gpt-4, gpt-3.5-turbo

# Option 2: Anthropic Claude
# ANTHROPIC_API_KEY=sk-ant-your-key-here
# MODEL_NAME=claude-3-5-sonnet-20241022
# Other options: claude-3-opus-20240229, claude-3-sonnet-20240229

# Option 3: Mistral AI
# MISTRAL_API_KEY=your-mistral-key-here
# MODEL_NAME=mistral-large-latest
# Other options: mistral-medium-latest, mistral-small-latest, open-mistral-7b

# Option 4: Local Ollama (Free, no API key needed!)
# MODEL_NAME=llama3.2
# Other options: mistral, llama2, codellama
# Note: Requires Ollama installed and running locally
# Note: Use "mistral" (no dash) for Ollama, "mistral-large" for Mistral API

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# For Mistral embeddings: mistral-embed
# Note: Mistral embeddings require MISTRAL_API_KEY
EMBEDDING_DIMENSION=384

# FAISS Configuration
FAISS_INDEX_TYPE=IVFFlat
FAISS_NLIST=100
FAISS_NPROBE=10

# Application Settings
LOG_LEVEL=INFO
MAX_CHUNK_SIZE=512
CHUNK_OVERLAP=50
TOP_K_RESULTS=5

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
